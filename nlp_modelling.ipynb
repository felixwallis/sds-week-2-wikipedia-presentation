{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Opinion Mining on Wiki Text (Modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing Required Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Shreyansh\n",
      "[nltk_data]     Padarha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "c:\\Users\\Shreyansh Padarha\\Documents\\GitHub\\sds-week-2-wikipedia-presentation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Segregated Dataset into the Environment\n",
    "__Pre-Processed in ```pre_processing.ipynb```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('Data/wikiarticles_seg_data.feather')\n",
    "\n",
    "# Combining month and year into a datetime column\n",
    "df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))\n",
    "\n",
    "# Not considering the References category\n",
    "df = df[df.category != 'References']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage split of articles\n",
      "article_name\n",
      "Vladimir Putin    81.686076\n",
      "Xi Jinping        18.313924\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "article_counts = df['article_name'].value_counts()\n",
    "\n",
    "# Calculating the percentage split\n",
    "print(\"Percentage split of articles\")\n",
    "print((article_counts / article_counts.sum()) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Only taking One Revision/Version Per Month__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the maximum file_id for each month-year-article_name combination\n",
    "max_file_ids = (\n",
    "    df.groupby(['month', 'year', 'article_name'])['file_id']\n",
    "    .transform('max')\n",
    ")\n",
    "\n",
    "# Filtering rows where file_id is equal to the maximum file_id for its group\n",
    "filtered_df = df[df['file_id'] == max_file_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage split of articles after filtering\n",
      "article_name\n",
      "Vladimir Putin    67.814162\n",
      "Xi Jinping        32.185838\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "article_counts_new = filtered_df['article_name'].value_counts()\n",
    "print(\"Percentage split of articles after filtering\")\n",
    "print((article_counts_new / article_counts_new.sum()) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>article_name</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Policies</td>\n",
       "      <td>On  March , Putin won the  Russian presidentia...</td>\n",
       "      <td>547791410</td>\n",
       "      <td>03</td>\n",
       "      <td>2013</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>policy</td>\n",
       "      <td>2013-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191575</th>\n",
       "      <td>Electoral history</td>\n",
       "      <td>, a monument to victims of Stalinist repressio...</td>\n",
       "      <td>1036447862</td>\n",
       "      <td>07</td>\n",
       "      <td>2021</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Assessment</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119442</th>\n",
       "      <td>Putin-related humour</td>\n",
       "      <td>Putin on Chechen extremists, on September , : ...</td>\n",
       "      <td>61342827</td>\n",
       "      <td>06</td>\n",
       "      <td>2006</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Public Imaage</td>\n",
       "      <td>2006-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title  \\\n",
       "206                 Policies   \n",
       "191575     Electoral history   \n",
       "119442  Putin-related humour   \n",
       "\n",
       "                                                     text     file_id month  \\\n",
       "206     On  March , Putin won the  Russian presidentia...   547791410    03   \n",
       "191575  , a monument to victims of Stalinist repressio...  1036447862    07   \n",
       "119442  Putin on Chechen extremists, on September , : ...    61342827    06   \n",
       "\n",
       "        year    article_name       category       date  \n",
       "206     2013  Vladimir Putin         policy 2013-03-01  \n",
       "191575  2021  Vladimir Putin     Assessment 2021-07-01  \n",
       "119442  2006  Vladimir Putin  Public Imaage 2006-06-01  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Assessment\n",
    "\n",
    "### Implementation using **Dbias** - Detecting Bias and ensuring Fairness in AI solutions\n",
    "\n",
    "To detect bias and fairness in sentences, the Dbias classification model was employed. This model was trained on the MBIC (Media Bias Identification Corpus) Dataset by the researchers, leveraging the DistilBERT-base-uncased model as its foundation. Training was conducted for 30 epochs, with a batch size of 16, a learning rate of 5e-5, and a maximum sequence length set to 512 tokens. This setup enables the model to effectively assess bias and fairness in text, particularly within news articles, providing insights based on the nuances captured in the training dataset.\n",
    "\n",
    "**Credit**<br>\n",
    "Raza, S., Reji, D. J., & Ding, C. (2022). Dbias: Detecting biases and ensuring fairness in news articles.<br>\n",
    "*International Journal of Data Science and Analytics*, 1-21. Springer. https://doi.org/10.1007/s41060-022-00359-4\n",
    "\n",
    "**Github Repo Link:** https://github.com/dreji18/Fairness-in-AI/tree/main\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dbias.bias_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'Biased', 'score': 0.9938021898269653}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# returns classification label for a given sentence fragment. (Sample Test)\n",
    "classifier(\"Nevertheless, Trump and other Republicans have tarred the protests as havens for terrorists intent on destroying property.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_and_classify(corpus, chunk_size=250, overlap=50):\n",
    "    \"\"\"\n",
    "    Splits the corpus into overlapping chunks, classifies each chunk as 'Biased' or 'Non-biased',\n",
    "    assigns a score based on the classification, and averages the scores.\n",
    "    \n",
    "    Parameters:\n",
    "    - corpus (str): The text corpus to be chunked and classified.\n",
    "    - chunk_size (int): Number of base tokens per chunk.\n",
    "    - overlap (int): Number of overlapping tokens between consecutive chunks.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (float, str) The average score of all chunks and the final classification.\n",
    "    \"\"\"\n",
    "    tokens = corpus.split()  # Tokenize corpus (use actual tokenizer if needed)\n",
    "    chunk_scores = []\n",
    "    \n",
    "    try:\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            # Create a chunk with overlap\n",
    "            chunk = tokens[i:i + chunk_size + overlap]\n",
    "            chunk_text = \" \".join(chunk)\n",
    "            \n",
    "            # Classify chunk\n",
    "            result = classifier(chunk_text)[0]\n",
    "            score = result['score']\n",
    "            \n",
    "            # Adjust score based on label\n",
    "            if result['label'] == 'Non-biased':\n",
    "                chunk_scores.append(score)  # Keep score as positive\n",
    "            elif result['label'] == 'Biased':\n",
    "                chunk_scores.append(-score)  # Make score negative\n",
    "\n",
    "            # Move index forward by chunk_size to get the next chunk\n",
    "            i += chunk_size\n",
    "            \n",
    "    except:\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            # Create a chunk with overlap\n",
    "            chunk = tokens[i:i + chunk_size-100 + overlap-25]\n",
    "            chunk_text = \" \".join(chunk)\n",
    "            \n",
    "            # Classify chunk\n",
    "            result = classifier(chunk_text)[0]\n",
    "            score = result['score']\n",
    "            \n",
    "            # Adjust score based on label\n",
    "            if result['label'] == 'Non-biased':\n",
    "                chunk_scores.append(score)  # Keep score as positive\n",
    "            elif result['label'] == 'Biased':\n",
    "                chunk_scores.append(-score)  # Make score negative\n",
    "\n",
    "            # Move index forward by chunk_size to get the next chunk\n",
    "            i += chunk_size\n",
    "\n",
    "    # Calculate the average score of all chunks\n",
    "    average_score = np.mean(chunk_scores)\n",
    "    final_classification = \"Non-biased\" if average_score >= 0 else \"Biased\"\n",
    "    \n",
    "    return average_score, final_classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[['bias_score', 'bias_class']] = filtered_df['text'].apply(\n",
    "    lambda corpus: pd.Series(chunk_and_classify(corpus, chunk_size=250, overlap=50))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>article_name</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>bias_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199256</th>\n",
       "      <td>Foreign policy</td>\n",
       "      <td>Putin's domestic policies, particularly early ...</td>\n",
       "      <td>981043171</td>\n",
       "      <td>09</td>\n",
       "      <td>2020</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Public Imaage</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>-0.637244</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295467</th>\n",
       "      <td>Leadership</td>\n",
       "      <td>in August ]] on  September ]] Xi was appointed...</td>\n",
       "      <td>991542613</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>Xi Jinping</td>\n",
       "      <td>Leadership Tenures</td>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>-0.516696</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73404</th>\n",
       "      <td>Third Presidency (2012–present)</td>\n",
       "      <td>]] Putin was barred from a third term by the C...</td>\n",
       "      <td>520098174</td>\n",
       "      <td>10</td>\n",
       "      <td>2012</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Leadership Tenures</td>\n",
       "      <td>2012-10-01</td>\n",
       "      <td>-0.743318</td>\n",
       "      <td>Biased</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "199256                   Foreign policy   \n",
       "295467                       Leadership   \n",
       "73404   Third Presidency (2012–present)   \n",
       "\n",
       "                                                     text    file_id month  \\\n",
       "199256  Putin's domestic policies, particularly early ...  981043171    09   \n",
       "295467  in August ]] on  September ]] Xi was appointed...  991542613    11   \n",
       "73404   ]] Putin was barred from a third term by the C...  520098174    10   \n",
       "\n",
       "        year    article_name            category       date  bias_score  \\\n",
       "199256  2020  Vladimir Putin       Public Imaage 2020-09-01   -0.637244   \n",
       "295467  2020      Xi Jinping  Leadership Tenures 2020-11-01   -0.516696   \n",
       "73404   2012  Vladimir Putin  Leadership Tenures 2012-10-01   -0.743318   \n",
       "\n",
       "       bias_class  \n",
       "199256     Biased  \n",
       "295467     Biased  \n",
       "73404      Biased  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC Lexical Corpus - Emotion Analysis\n",
    "\n",
    "The NRC Emotion Lexicon is a collection of English words linked to eight primary emotions—anger, fear, anticipation, trust, surprise, sadness, joy, and disgust—as well as two sentiments, positive and negative. These annotations were crowdsourced through manual contributions.\n",
    "\n",
    "Despite being nearly **15 years** old, its relevance remains highly regarded and respected among researchers. Numerous applied NLP studies over the past five years continue to incorporate it in their work.\n",
    "\n",
    "**Credit**<br>\n",
    "Mohammad, S., & Turney, P. (2010). Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text (pp. 26–34). Association for Computational Linguistics. https://aclanthology.org/W10-0204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmotionAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the TextEmotionAnalyzer class by loading the NRC Emotion Lexicon.\n",
    "        The lexicon is pivoted to create an easy lookup structure for emotion associations.\n",
    "        \"\"\"\n",
    "        # Load the NRC Emotion Lexicon from a specified path into a DataFrame.\n",
    "        self.df_emotions = pd.read_csv(\n",
    "            \"Data\\\\NRC Word-Emotion Association Lexicon\\\\NRC-Sentiment-Emotion-Lexicons\\\\NRC-Emotion-Lexicon-v0.92\\\\NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\",\n",
    "            names=[\"word\", \"emotion\", \"association\"],  # Assign column names for better clarity.\n",
    "            sep='\\t'  # Specify that the file is tab-separated.\n",
    "        )\n",
    "        \n",
    "        # Pivot the DataFrame to have words as index and emotions as columns, with associations as values.\n",
    "        self.df_emotion_word = self.df_emotions.pivot(index='word', columns='emotion', values='association').fillna(0)\n",
    "        \n",
    "        # Get a list of all emotions from the pivoted DataFrame's columns.\n",
    "        self.emotions = self.df_emotion_word.columns.tolist()\n",
    "        \n",
    "        # Initialize the Snowball Stemmer for English to help with word stemming.\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "    def get_emotion_scores(self, text):\n",
    "        \"\"\"\n",
    "        Analyzes the input text and computes the emotion scores based on the NRC Emotion Lexicon.\n",
    "        \n",
    "        Parameters:\n",
    "            text (str): The input text to analyze for emotions.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with emotions as keys and their associated scores as values.\n",
    "        \"\"\"\n",
    "        # Preprocess the input text by removing non-alphanumeric characters (keeping spaces).\n",
    "        processed_text = re.sub(r\"[^a-zA-Z0-9 ]+\", '', text)\n",
    "        \n",
    "        # Tokenize the processed text into individual words and convert to lowercase.\n",
    "        tokens = word_tokenize(processed_text.lower())\n",
    "        \n",
    "        # Initialize a dictionary to store emotion scores, starting at 0 for each emotion.\n",
    "        emotion_scores = dict.fromkeys(self.emotions, 0)\n",
    "        \n",
    "        # Calculate emotion scores based on the tokens in the input text.\n",
    "        for word in tokens:\n",
    "            # Stem the current word to its root form for better matching with the lexicon.\n",
    "            stemmed_word = self.stemmer.stem(word)\n",
    "            \n",
    "            # Check if the stemmed word exists in the emotion word DataFrame index.\n",
    "            if stemmed_word in self.df_emotion_word.index:\n",
    "                # Retrieve the emotion score for the stemmed word.\n",
    "                emotion_score = self.df_emotion_word.loc[stemmed_word]\n",
    "                \n",
    "                # Update the total emotion scores for each emotion.\n",
    "                for emotion in self.emotions:\n",
    "                    emotion_scores[emotion] += emotion_score[emotion]\n",
    "\n",
    "        # Normalize the emotion scores by the total number of words if the word count is greater than 0.\n",
    "        word_count = len(tokens)\n",
    "        if word_count > 0:\n",
    "            emotion_scores = {emotion: score / word_count for emotion, score in emotion_scores.items()}\n",
    "        else:\n",
    "            # If no words are found, set all emotion scores to 0.\n",
    "            emotion_scores = {emotion: 0 for emotion in emotion_scores}\n",
    "\n",
    "        return emotion_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TextEmotionAnalyzer\n",
    "analyzer = TextEmotionAnalyzer()\n",
    "\n",
    "# Apply emotion analysis to each row's text and add results as new columns\n",
    "emotion_columns = [f\"{emotion}_emotion\" for emotion in analyzer.emotions]\n",
    "\n",
    "# Analyze each text and store the result in a new DataFrame\n",
    "emotion_scores_df = filtered_df['text'].apply(analyzer.get_emotion_scores).apply(pd.Series)\n",
    "emotion_scores_df.columns = emotion_columns\n",
    "\n",
    "# Merge the new emotion scores with the original DataFrame\n",
    "filtered_df = pd.concat([filtered_df, emotion_scores_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>article_name</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>bias_class</th>\n",
       "      <th>anger_emotion</th>\n",
       "      <th>anticipation_emotion</th>\n",
       "      <th>disgust_emotion</th>\n",
       "      <th>fear_emotion</th>\n",
       "      <th>joy_emotion</th>\n",
       "      <th>negative_emotion</th>\n",
       "      <th>positive_emotion</th>\n",
       "      <th>sadness_emotion</th>\n",
       "      <th>surprise_emotion</th>\n",
       "      <th>trust_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238857</th>\n",
       "      <td>Family and personal life</td>\n",
       "      <td>President Alexander Lukashenka.]] While Presid...</td>\n",
       "      <td>27017765</td>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Personal Details</td>\n",
       "      <td>2005-10-01</td>\n",
       "      <td>-0.833512</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.007614</td>\n",
       "      <td>0.045685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198532</th>\n",
       "      <td>Public image</td>\n",
       "      <td>in Bishkek.]] Leonid Bershidsky analyzed Putin...</td>\n",
       "      <td>985853861</td>\n",
       "      <td>10</td>\n",
       "      <td>2020</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Public Imaage</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>-0.710769</td>\n",
       "      <td>Biased</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.020036</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.034728</td>\n",
       "      <td>0.043188</td>\n",
       "      <td>0.014693</td>\n",
       "      <td>0.009350</td>\n",
       "      <td>0.033393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186957</th>\n",
       "      <td>Honours</td>\n",
       "      <td>at their wedding,  July ]] On  July , Putin ma...</td>\n",
       "      <td>912352343</td>\n",
       "      <td>08</td>\n",
       "      <td>2019</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Recognition</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>0.159827</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.057287</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>0.046335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "238857  Family and personal life   \n",
       "198532              Public image   \n",
       "186957                   Honours   \n",
       "\n",
       "                                                     text    file_id month  \\\n",
       "238857  President Alexander Lukashenka.]] While Presid...   27017765    10   \n",
       "198532  in Bishkek.]] Leonid Bershidsky analyzed Putin...  985853861    10   \n",
       "186957  at their wedding,  July ]] On  July , Putin ma...  912352343    08   \n",
       "\n",
       "        year    article_name          category       date  bias_score  \\\n",
       "238857  2005  Vladimir Putin  Personal Details 2005-10-01   -0.833512   \n",
       "198532  2020  Vladimir Putin     Public Imaage 2020-10-01   -0.710769   \n",
       "186957  2019  Vladimir Putin       Recognition 2019-08-01    0.159827   \n",
       "\n",
       "        bias_class  anger_emotion  anticipation_emotion  disgust_emotion  \\\n",
       "238857      Biased       0.005076              0.020305         0.000000   \n",
       "198532      Biased       0.015138              0.020036         0.008905   \n",
       "186957  Non-biased       0.005897              0.024431         0.000842   \n",
       "\n",
       "        fear_emotion  joy_emotion  negative_emotion  positive_emotion  \\\n",
       "238857      0.007614     0.007614          0.017766          0.043147   \n",
       "198532      0.020036     0.010686          0.034728          0.043188   \n",
       "186957      0.006740     0.022746          0.014322          0.057287   \n",
       "\n",
       "        sadness_emotion  surprise_emotion  trust_emotion  \n",
       "238857         0.002538          0.007614       0.045685  \n",
       "198532         0.014693          0.009350       0.033393  \n",
       "186957         0.008425          0.012637       0.046335  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## BERT Based **Political Leaning Identification**\n",
    "\n",
    "**Reference**\n",
    "1. Conference Proceedings <br>\n",
    "Baly, R., Da San Martino, G., Glass, J., & Nakov, P. (2020). We can detect your bias: Predicting the political ideology of news articles. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 4982–4991). Association for Computational Linguistics.\n",
    "\n",
    "2. Article <br>\n",
    "Bucket Research. (2023). Political bias classification using finetuned BERT model.\n",
    "\n",
    "3. HuggingFace Repo Link <br>\n",
    "https://huggingface.co/bucketresearch/politicalBiasBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Month Wise Topic Modelling__ (Career, Policies, etc.)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT model and tokenizer for sequence classification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bucketresearch/politicalBiasBERT\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bucketresearch/politicalBiasBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test_political_lean returns exactly three values\n",
    "def test_political_lean(text):\n",
    "    max_length = 512\n",
    "\n",
    "    # Tokenize text in chunks and store the results\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=max_length)\n",
    "    chunked_logits = []\n",
    "\n",
    "    # Process each chunk and aggregate logits\n",
    "    for i in range(0, len(inputs['input_ids'][0]), max_length):\n",
    "        chunk_input = {key: val[:, i:i + max_length] for key, val in inputs.items()}\n",
    "        outputs = model(**chunk_input, labels=torch.tensor([0]))  # Adjust `labels` if needed\n",
    "        _, logits = outputs[:2]\n",
    "        chunked_logits.append(logits)\n",
    "\n",
    "    # Aggregate results (e.g., averaging logits across chunks if it's classification)\n",
    "    final_logits = torch.mean(torch.stack(chunked_logits), dim=0)\n",
    "    loss, logits = outputs[:2]\n",
    "    left, centre, right = logits.softmax(dim=-1)[0].tolist()  # Left, Center, Right\n",
    "    \n",
    "    # Return as a tuple\n",
    "    return left, centre, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying function and store results in separate columns\n",
    "filtered_df[['left_lean', 'center_lean', 'right_lean']] = filtered_df['text'].apply(\n",
    "    lambda corpus: pd.Series(test_political_lean(corpus))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>file_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>article_name</th>\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>bias_class</th>\n",
       "      <th>...</th>\n",
       "      <th>fear_emotion</th>\n",
       "      <th>joy_emotion</th>\n",
       "      <th>negative_emotion</th>\n",
       "      <th>positive_emotion</th>\n",
       "      <th>sadness_emotion</th>\n",
       "      <th>surprise_emotion</th>\n",
       "      <th>trust_emotion</th>\n",
       "      <th>left_lean</th>\n",
       "      <th>center_lean</th>\n",
       "      <th>right_lean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240988</th>\n",
       "      <td>Quotations</td>\n",
       "      <td>One of Putin's favorite sports is the martial ...</td>\n",
       "      <td>17911161</td>\n",
       "      <td>06</td>\n",
       "      <td>2005</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Communications</td>\n",
       "      <td>2005-06-01</td>\n",
       "      <td>0.530233</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.517628</td>\n",
       "      <td>0.261512</td>\n",
       "      <td>0.220860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85055</th>\n",
       "      <td>Early years and KGB career</td>\n",
       "      <td>30T23::45Z Krawndawg  Mistranslation...?  wiki...</td>\n",
       "      <td>209344256</td>\n",
       "      <td>04</td>\n",
       "      <td>2008</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Carreer Progression</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>-0.705010</td>\n",
       "      <td>Biased</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.969789</td>\n",
       "      <td>0.010116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135860</th>\n",
       "      <td>Early years and KGB career</td>\n",
       "      <td>31T23::16Z Paul Pieniezny  Deleting text by Ma...</td>\n",
       "      <td>168402573</td>\n",
       "      <td>10</td>\n",
       "      <td>2007</td>\n",
       "      <td>Vladimir Putin</td>\n",
       "      <td>Carreer Progression</td>\n",
       "      <td>2007-10-01</td>\n",
       "      <td>-0.730894</td>\n",
       "      <td>Biased</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.134062</td>\n",
       "      <td>0.853728</td>\n",
       "      <td>0.012211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  \\\n",
       "240988                  Quotations   \n",
       "85055   Early years and KGB career   \n",
       "135860  Early years and KGB career   \n",
       "\n",
       "                                                     text    file_id month  \\\n",
       "240988  One of Putin's favorite sports is the martial ...   17911161    06   \n",
       "85055   30T23::45Z Krawndawg  Mistranslation...?  wiki...  209344256    04   \n",
       "135860  31T23::16Z Paul Pieniezny  Deleting text by Ma...  168402573    10   \n",
       "\n",
       "        year    article_name             category       date  bias_score  \\\n",
       "240988  2005  Vladimir Putin       Communications 2005-06-01    0.530233   \n",
       "85055   2008  Vladimir Putin  Carreer Progression 2008-04-01   -0.705010   \n",
       "135860  2007  Vladimir Putin  Carreer Progression 2007-10-01   -0.730894   \n",
       "\n",
       "        bias_class  ...  fear_emotion  joy_emotion  negative_emotion  \\\n",
       "240988  Non-biased  ...      0.013889     0.027778          0.013889   \n",
       "85055       Biased  ...      0.010309     0.012371          0.020619   \n",
       "135860      Biased  ...      0.000000     0.022222          0.000000   \n",
       "\n",
       "        positive_emotion  sadness_emotion  surprise_emotion  trust_emotion  \\\n",
       "240988          0.062500         0.013889          0.020833       0.041667   \n",
       "85055           0.053608         0.008247          0.012371       0.043299   \n",
       "135860          0.055556         0.000000          0.022222       0.033333   \n",
       "\n",
       "        left_lean  center_lean  right_lean  \n",
       "240988   0.517628     0.261512    0.220860  \n",
       "85055    0.020095     0.969789    0.010116  \n",
       "135860   0.134062     0.853728    0.012211  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to Feather For Further Analysis/Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_feather('Data/wikiarticles_opinion_mining_results.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
